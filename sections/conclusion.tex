%% LaTeX2e class for student theses
%% sections/conclusion.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.1, 2014-11-21

\chapter{Conclusion}
\label{ch:Conclusion}

The aim of this thesis was to present an approach to Language Identification (LID) in an online-environment based on Neural Networks. We evaluated our results with three different corpora: The Euronews 2014 corpus, the Lecture Data corpus as collected from the KIT's lecture recordings and talks at Interact25, DGA and a small corpus we collected of European Parliament speeches with their simultaneous translations.

Overall, we have found a feasible approach to Language Identification (LID) in an online-environment. Our setup included a DNBF net to preprocess stacked AFs. The extracted BNFs were stacked with a context and then fed into our LID DNN.  We tried DNNs in different setups and net layouts. In general, we can conclude that DNNs are a feasible solution to the LID problem. On our Euronews corpus, for samples longer than 500ms, we achieved an adjusted error rate of 16 \% for the tree-net structure with 6 layers that performed the best. This means usage of the net in an online-environment like the lecture translator is feasible.

In a further step we also tried out different net structures on our two other corpora: the European Parliament speeches and Lecture Recordings. It was confirmed that the tree-net structure appears to fare the best to identify languages. We also found, that even with a minimal training corpus, as in the case of European Parliament, DNNs are still a feasible classification mechanism, featuring an error of (on samples of any length), only 35 \% for a corpus of only 1.5h per language. 

Afterwards we evaluated different filtering approaches to be able to smooth out our LID net output further in an online-environment. Overall a counting filter, sequence and Gauss filter appear to produce the best results. We defined our own metric, the Out-of-Language Filter as to rate the ``noisiness'' reduction of a filter. The counting filter features a relative improvement of the Out-Of-Language-Error of 97 \% compared to not using a filter. However it would increase delay to 1.5 seconds, which might be considered too big in an online-setting. The Gauss and sequence filter, with a much smaller delay of only 150/100 ms respectively, would still future a big improvement however and could also be employed to great success.

We conclude, that the usage of DNNs to recognize language proved successful. As to a possible implementation in the Lecture Translator: the best results were achieved by using a combination of the lecture data and Euronews corpus (section~\ref{sec:LIDNetworkConcat}), as this provided the best results. However, it is likely the results of a lecture-data-only net would prove to be better with a bigger train corpus. Overall, from the results in this thesis, the usage of the concatenated corpus and use of a selection/combination of our post-processing filters to further smooth data, would provide the best results. A result of an error rate of only 6.5\% would certainly be small enough to prove helpful in improving the Lecture Translator in a multilingual environment.

\section{Future Work}
\label{sec:fw}

Future work to further improve the results and findings of this thesis could include:

RNNs have recently outperformed DNNs in Language Identification~\cite{gonzalez2014automatic}, so further experiments with the presented pre-/post-processing setup and RNNs instead of DNNs could improve upon our results.

While our findings in regards to the network architecture and setup have been shown to be generic enough to be applicable to three different data corpora, further work should be done to confirm our findings. Especially the post-processing findings should be tested on further (larger) corpora and nets.

Post-Processing in an online-environment has been found to be a non-trivial problem, as can be seen on our two filter metrics diverging. As post-processing is often not the content of other works, future work could test out our results in a concrete online implementation, including and extending the post-processing approaches presented in this thesis.